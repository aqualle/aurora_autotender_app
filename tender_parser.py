import time
import logging
import json
import re
import tempfile
import shutil
import uuid
import atexit
import signal
import os
import sys
from typing import Dict, Optional, List, Any
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.edge.service import Service
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, WebDriverException
from utils import extract_products_from_excel, save_results_into_tender_format
import subprocess
import requests
import zipfile
import io
from pathlib import Path
SEARCH_URL_TEMPLATE = "https://market.yandex.ru/search?text={query}"


def _normalize_search_term(search_term: str, max_len: int = 120) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –ø–æ–∏—Å–∫–∞ –ø–µ—Ä–µ–¥ –≤–≤–æ–¥–æ–º –≤ –º–∞—Ä–∫–µ—Ç."""
    cleaned = re.sub(r"\s+", " ", str(search_term or "")).strip()
    return cleaned[:max_len]


def _perform_direct_search_navigation(driver, search_term: str) -> bool:
    """Fallback: –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ URL –ø–æ–∏—Å–∫–∞."""
    normalized = _normalize_search_term(search_term)
    if not normalized:
        return False

    try:
        encoded_query = requests.utils.quote(normalized)
        driver.get(SEARCH_URL_TEMPLATE.format(query=encoded_query))
        time.sleep(1.2)
        return "search" in driver.current_url
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–π—Ç–∏ –ø–æ –ø—Ä—è–º–æ–º—É URL –ø–æ–∏—Å–∫–∞: {e}")
        return False

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–æ–º –∏ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
STOP_PARSING = False
CREATED_PROFILES = set()
CURRENT_DATAFRAME = None
CURRENT_OUTPUT_FILE = None
CURRENT_INPUT_FILE = None

def setup_signal_handlers():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    def signal_handler(signum, frame):
        global STOP_PARSING
        logger.info(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è ({signum}), –≤—ã–ø–æ–ª–Ω—è—é –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...")
        STOP_PARSING = True
        force_save_results()
        cleanup_profiles()
        logger.info("–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –≤—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã")
        os._exit(0)

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è Windows –∏ Unix
    try:
        signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # Terminate
        if hasattr(signal, 'SIGBREAK'):  # Windows
            signal.signal(signal.SIGBREAK, signal_handler)
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

def force_save_results():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    global CURRENT_DATAFRAME, CURRENT_OUTPUT_FILE, CURRENT_INPUT_FILE

    if CURRENT_DATAFRAME is not None and CURRENT_OUTPUT_FILE and CURRENT_INPUT_FILE:
        try:
            # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
            processed = len([r for r in CURRENT_DATAFRAME['—Ü–µ–Ω–∞'] if r and r not in ['', '–û–®–ò–ë–ö–ê']])
            total = len(CURRENT_DATAFRAME)

            # –ò–°–ü–û–õ–¨–ó–£–ï–ú –ù–û–í–£–Æ –§–£–ù–ö–¶–ò–Æ –¢–ï–ù–î–ï–†–ù–û–ì–û –§–û–†–ú–ê–¢–ê
            save_results_into_tender_format(CURRENT_INPUT_FILE, CURRENT_OUTPUT_FILE, CURRENT_DATAFRAME)
            logger.info(f"–≠–ö–°–¢–†–ï–ù–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï –¢–ï–ù–î–ï–†–ê: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{total} —Ç–æ–≤–∞—Ä–æ–≤ –≤ {CURRENT_OUTPUT_FILE}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
    else:
        logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

def stop_all_parsing():
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    global STOP_PARSING
    STOP_PARSING = True
    logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞")

def cleanup_single_profile(profile_path: str) -> bool:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ –æ—á–∏—â–∞–µ—Ç –æ–¥–∏–Ω –ø—Ä–æ—Ñ–∏–ª—å Edge –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞"""
    if not profile_path or not os.path.exists(profile_path):
        return False

    try:
        time.sleep(0.3)

        try:
            import psutil
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] and 'msedge' in proc.info['name'].lower():
                        if proc.info['cmdline']:
                            cmdline = ' '.join(proc.info['cmdline'])
                            if profile_path in cmdline:
                                return False
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
        except ImportError:
            time.sleep(0.5)

        shutil.rmtree(profile_path, ignore_errors=True)
        success = not os.path.exists(profile_path)

        return success

    except Exception as e:
        return False

def cleanup_profiles():
    """–ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
    global CREATED_PROFILES
    cleanup_count = 0
    for profile_path in CREATED_PROFILES.copy():
        try:
            if os.path.exists(profile_path):
                shutil.rmtree(profile_path, ignore_errors=True)
                cleanup_count += 1
        except:
            pass
    CREATED_PROFILES.clear()
    if cleanup_count > 0:
        logger.info(f"–û—á–∏—â–µ–Ω–æ {cleanup_count} –ø—Ä–æ—Ñ–∏–ª–µ–π Edge")

atexit.register(cleanup_profiles)

def kill_zombie_edges():
    """–£–±–∏–≤–∞–µ—Ç Edge –ø—Ä–æ—Ü–µ—Å—Å—ã"""
    print("–ó–∞–∫—Ä—ã–≤–∞—é Edge –ø—Ä–æ—Ü–µ—Å—Å—ã...")
    try:
        import psutil
        killed_count = 0
        for p in psutil.process_iter(['pid', 'name']):
            if p.info['name'] and 'msedge' in p.info['name'].lower():
                try:
                    p.terminate()
                    killed_count += 1
                except:
                    pass
        if killed_count > 0:
            print(f"–ó–∞–∫—Ä—ã—Ç–æ {killed_count} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
    except:
        pass

EDGE_VERSION = "144.0.3719.82"

def ensure_edgedriver(driver_dir: Path) -> Path:
    driver_dir.mkdir(parents=True, exist_ok=True)
    driver_path = driver_dir / "msedgedriver.exe"

    # –ë–µ—Ä—ë–º –æ—Å–Ω–æ–≤–Ω—É—é —á–∞—Å—Ç—å –≤–µ—Ä—Å–∏–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    edge_major = EDGE_VERSION.split('.')[0]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥—Ä–∞–π–≤–µ—Ä –∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –≤–µ—Ä—Å–∏—è
    if driver_path.exists():
        try:
            out = subprocess.check_output(
                f'"{driver_path}" --version', shell=True, text=True
            )
            if edge_major in out:
                return driver_path
        except Exception:
            pass

    # –°–∫–∞—á–∏–≤–∞–µ–º –Ω—É–∂–Ω—ã–π –¥—Ä–∞–π–≤–µ—Ä
    url = f"https://msedgedriver.azureedge.net/{EDGE_VERSION}/edgedriver_win64.zip"
    r = requests.get(url, timeout=30)
    r.raise_for_status()

    with zipfile.ZipFile(io.BytesIO(r.content)) as z:
        z.extract("msedgedriver.exe", driver_dir)

    return driver_path

def _get_chrome_major_version() -> str:
    output = subprocess.check_output(
        r'reg query "HKLM\SOFTWARE\Google\Chrome\BLBeacon" /v version',
        shell=True,
        text=True
    )
    return re.search(r'(\d+)\.', output).group(1)

def ensure_chromedriver(driver_dir: Path) -> Path:
    driver_dir.mkdir(parents=True, exist_ok=True)
    driver_path = driver_dir / "chromedriver.exe"

    chrome_major = _get_chrome_major_version()

    if driver_path.exists():
        try:
            out = subprocess.check_output(
                f'"{driver_path}" --version', shell=True, text=True
            )
            if chrome_major in out:
                return driver_path
        except Exception:
            pass

    # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é Chrome for Testing
    versions_url = "https://googlechromelabs.github.io/chrome-for-testing/latest-patch-versions-per-build.json"
    data = requests.get(versions_url, timeout=30).json()

    full_version = data["builds"][chrome_major]["version"]

    download_url = (
        f"https://storage.googleapis.com/chrome-for-testing-public/"
        f"{full_version}/win64/chromedriver-win64.zip"
    )

    r = requests.get(download_url, timeout=30)
    r.raise_for_status()

    with zipfile.ZipFile(io.BytesIO(r.content)) as z:
        for name in z.namelist():
            if name.endswith("chromedriver.exe"):
                z.extract(name, driver_dir)
                extracted = driver_dir / name
                extracted.replace(driver_path)
                break

    return driver_path




def create_driver(
    headless: bool = True,
    driver_path: Optional[str] = None,
    use_auth: bool = False,
    browser: str = "edge"
):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ Edge / Chrome —Å –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–æ–º WebDriver
    """
    global CREATED_PROFILES

    profile_dir = None

    if browser == "edge":
        options = webdriver.EdgeOptions()
    elif browser == "chrome":
        options = webdriver.ChromeOptions()
    else:
        raise ValueError("browser –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'edge' –∏–ª–∏ 'chrome'")

    common_args = [
        "--no-sandbox",
        "--disable-dev-shm-usage",
        "--disable-gpu",
        "--disable-extensions",
        "--disable-plugins",
        "--disable-web-security",
        "--no-default-browser-check",
        "--no-first-run",
        "--disable-default-apps",
        "--disable-sync",
        "--disable-logging",
        "--log-level=3",
        "--silent",
    ]

    for arg in common_args:
        options.add_argument(arg)

    if use_auth:
        timestamp = int(time.time() * 1000)
        worker_id = uuid.uuid4().hex[:8]
        app_dir = Path.home() / ".yandex_parser_auth"
        app_dir.mkdir(exist_ok=True)

        profile_dir = app_dir / f"{browser}_profile_{worker_id}_{timestamp}"
        profile_dir.mkdir(parents=True, exist_ok=True)
        options.add_argument(f"--user-data-dir={profile_dir}")
        CREATED_PROFILES.add(str(profile_dir))
    else:
        temp_dir = tempfile.mkdtemp(prefix=f"{browser}_temp_{uuid.uuid4().hex[:8]}_")
        options.add_argument(f"--user-data-dir={temp_dir}")
        CREATED_PROFILES.add(temp_dir)


    if headless:
        options.add_argument("--headless=new")
        options.add_argument("--window-size=1280,800")

    try:
        base_dir = Path(__file__).parent / "browserdriver"
        base_dir.mkdir(exist_ok=True)

        custom_driver = Path(driver_path).expanduser() if driver_path else None
        if custom_driver and not custom_driver.exists():
            raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω —É–∫–∞–∑–∞–Ω–Ω—ã–π –¥—Ä–∞–π–≤–µ—Ä: {custom_driver}")

        if browser == "edge":
            driver_exe = custom_driver if custom_driver else ensure_edgedriver(base_dir)
            service = Service(str(driver_exe))
            driver = webdriver.Edge(service=service, options=options)

        else:  # chrome
            from selenium.webdriver.chrome.service import Service as ChromeService
            driver_exe = custom_driver if custom_driver else ensure_chromedriver(base_dir)
            service = ChromeService(str(driver_exe))
            driver = webdriver.Chrome(service=service, options=options)

        driver.set_page_load_timeout(15)
        driver.implicitly_wait(3)
        driver.profile_path = str(profile_dir) if profile_dir else temp_dir

        return driver

    except Exception as e:
        if profile_dir and str(profile_dir) in CREATED_PROFILES:
            try:
                shutil.rmtree(profile_dir, ignore_errors=True)
                CREATED_PROFILES.discard(str(profile_dir))
            except:
                pass

        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ ({browser}): {e}")
        raise



def load_cookies_for_auth(driver):
    """–ó–ê–ì–†–£–ó–ö–ê COOKIES –ò–ó –ü–ê–ü–ö–ò –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø (–ò–ó–ú–ï–ù–ï–ù–û –¢–û–õ–¨–ö–û –≠–¢–û)"""
    from pathlib import Path

    if STOP_PARSING:
        return False

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (.exe –∏–ª–∏ .py)
    if getattr(sys, 'frozen', False):
        app_dir = Path(sys.executable).parent
    else:
        app_dir = Path(os.path.abspath(__file__)).parent

    # –í–∞—Ä–∏–∞–Ω—Ç 1: cookies.json –≤ –∫–æ—Ä–Ω–µ –ø–∞–ø–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    cookies_file = app_dir / "cookies.json"

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫–æ—Ä–Ω–µ, –∏—â–µ–º –≤ .yandex_parser_auth (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    if not cookies_file.exists():
        cookies_file = Path.home() / ".yandex_parser_auth" / "cookies.json"

    if not cookies_file.exists():
        logger.warning(f"Cookies –ù–ï –Ω–∞–π–¥–µ–Ω—ã")
        return False

    try:
        with open(cookies_file, 'r', encoding='utf-8') as f:
            cookies_data = json.loads(f.read().strip())

        if isinstance(cookies_data, list):
            cookies = cookies_data
        elif isinstance(cookies_data, dict) and 'cookies' in cookies_data:
            cookies = cookies_data['cookies']
        else:
            return False

        driver.get("https://market.yandex.ru")
        time.sleep(0.5)

        loaded_count = 0
        for cookie in cookies:
            if STOP_PARSING:
                break

            try:
                if not isinstance(cookie, dict) or 'name' not in cookie or 'value' not in cookie:
                    continue

                clean_cookie = {
                    'name': str(cookie['name']),
                    'value': str(cookie['value']),
                    'path': str(cookie.get('path', '/'))
                }

                if 'domain' in cookie:
                    clean_cookie['domain'] = str(cookie['domain'])

                if cookie.get('secure', False):
                    clean_cookie['secure'] = True

                driver.add_cookie(clean_cookie)
                loaded_count += 1
            except:
                continue

        if loaded_count > 0:
            driver.refresh()
            time.sleep(0.5)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} cookies")
            return loaded_count > 0

        return False

    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ cookies: {e}")
        return False

def extract_prices_fast(driver):
    """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω: –º–∞—Å—Å–æ–≤–æ —Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–≤—ã–µ 4 ds.valueLine + –ø–æ–¥–ø–∏—Å–∏"""
    price_data = {
        '–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞': '',
        '—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü': ''
    }

    if STOP_PARSING:
        return price_data

    try:
        logger.debug("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞...")


        script = """
        var result = {
            prices: [],
            labels: []
        };

        var valuelines = document.querySelectorAll("span.ds-valueLine");
        var targetElements = Array.from(valuelines).slice(0, 4);

        for (var i = 0; i < targetElements.length; i++) {
            var element = targetElements[i];
            var priceText = element.textContent.trim();
            result.prices.push(priceText);

            // –ü–æ–∏—Å–∫ –ø–æ–¥–ø–∏—Å–µ–π –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            var labelText = "";
            var parent = element.parentElement;

            if (parent && parent.parentElement) {
                var textLines = parent.parentElement.querySelectorAll(".ds-textLine");
                for (var j = 0; j < Math.min(textLines.length, 3); j++) {
                    var text = textLines[j].textContent.trim().toLowerCase();
                    if (text && text.length < 25) {
                        labelText = text;
                        break;
                    }
                }
            }

            result.labels.push(labelText);
        }

        return result;
        """

        try:
            bulk_data = driver.execute_script(script)
        except Exception as e:
            logger.warning(f"JavaScript –æ—à–∏–±–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
            # Fallback
            all_valuelines = driver.find_elements(By.CSS_SELECTOR, "span.ds-valueLine")
            target_valuelines = all_valuelines[:4] if all_valuelines else []

            if not target_valuelines:
                return price_data

            bulk_data = {'prices': [], 'labels': []}
            for valueline in target_valuelines:
                bulk_data['prices'].append(valueline.text.strip())
                bulk_data['labels'].append("")

        if not bulk_data or not bulk_data.get('prices'):
            return price_data

        prices = bulk_data['prices']
        labels = bulk_data['labels']

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        prices_with_labels = []
        for i, (price_text, label_text) in enumerate(zip(prices, labels)):
            prices_with_labels.append({
                'text': price_text,
                'label': label_text.lower(),
                'index': i + 1
            })

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–æ–¥–ø–∏—Å—è–º
        regular_found = False
        vat_found = False

        # 1. –ò—â–µ–º "–ø—ç–π" –¥–ª—è –æ–±—ã—á–Ω–æ–π —Ü–µ–Ω—ã
        for item in prices_with_labels:
            if '–ø—ç–π' in item['label'] or 'pay' in item['label']:
                price_data['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞'] = item['text']
                regular_found = True
                break

        # 2. –ò—â–µ–º "—Å –ù–î–°" –¥–ª—è —é—Ä–ª–∏—Ü
        for item in prices_with_labels:
            if '—Å –Ω–¥—Å' in item['label'] or '–Ω–¥—Å' in item['label'] or '–¥–ª—è —é—Ä–ª–∏—Ü' in item['label']:
                price_data['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'] = item['text']
                vat_found = True
                break

        # 3. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ "–ø—ç–π" ‚Üí –ø–µ—Ä–≤–∞—è —Ü–µ–Ω–∞ –∫–∞–∫ –æ–±—ã—á–Ω–∞—è
        if not regular_found and prices_with_labels:
            price_data['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞'] = prices_with_labels[0]['text']

        return price_data

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–µ–Ω: {e}")
        return price_data

def extract_products_smart(driver) -> List[Dict[str, Any]]:
    products = []

    try:
        script = """
        const selectors = [
            'a[data-auto="snippet-link"]',
            'a[data-zone-name="title"]',
            'a[href*="/product--"]',
            'span[role="link"][data-auto="snippet-title"]'
        ];

        const nodes = [];
        selectors.forEach((selector) => {
            document.querySelectorAll(selector).forEach((node) => nodes.push(node));
        });

        const seen = new Set();
        const products = [];

        for (let i = 0; i < nodes.length; i++) {
            const node = nodes[i];
            const title = (node.textContent || '').trim();
            if (!title) continue;

            let link = node.closest('a[href]');
            if (!link && node.parentElement) {
                link = node.parentElement.querySelector('a[href]');
            }

            const rawUrl = link && link.href ? link.href : '';
            if (!rawUrl) continue;

            const normalizedUrl = rawUrl.split('?')[0];
            if (seen.has(normalizedUrl)) continue;
            seen.add(normalizedUrl);

            products.push({
                title: title,
                url: normalizedUrl,
                index: products.length + 1
            });

            if (products.length >= 6) break;
        }

        return products;
        """

        products_data = driver.execute_script(script, PRODUCT_LINK_SELECTORS)

        if products_data:
            products = [
                {
                    'title': p['title'],
                    'url': p['url'],
                    'index': p['index']
                }
                for p in products_data[:5]
                if p.get('url') and p.get('title')
            ]

        if products:
            logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            return products

    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤: {e}")

    return products

def parse_price_to_number(price_str: str) -> float:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Ü–µ–Ω—ã –≤ —á–∏—Å–ª–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    if not price_str:
        return float('inf')  # –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ü–µ–Ω

    try:
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, –∑–∞–ø—è—Ç—ã—Ö –∏ —Ç–æ—á–µ–∫
        clean_price = re.sub(r'[^\d,.]', '', price_str)

        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –¥–ª—è float
        clean_price = clean_price.replace(',', '.')

        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é)
        if clean_price.count('.') > 1:
            parts = clean_price.split('.')
            clean_price = ''.join(parts[:-1]) + '.' + parts[-1]

        return float(clean_price) if clean_price else float('inf')
    except:
        return float('inf')

def collect_prices_from_all_products(driver, products: List[Dict[str, Any]], search_term: str) -> Dict[str, str]:
    result = {"—Ü–µ–Ω–∞": "", "—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü": "", "—Å—Å—ã–ª–∫–∞": ""}

    if not products:
        logger.warning("–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return result

    # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ü–µ–Ω
    all_products_data = []

    logger.info(f"–°–æ–±–∏—Ä–∞—é —Ü–µ–Ω—ã —Å {len(products)} –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤:")

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –í–°–ï–ú —Ç–æ–≤–∞—Ä–∞–º –∏ —Å–æ–±–∏—Ä–∞–µ–º —Ü–µ–Ω—ã
    for i, product in enumerate(products, 1):
        if STOP_PARSING:
            break

        if not product.get('url'):
            logger.debug(f"–¢–æ–≤–∞—Ä {i}: –Ω–µ—Ç —Å—Å—ã–ª–∫–∏, –ø—Ä–æ–ø—É—Å–∫")
            continue

        try:
            short_title = product['title'][:45] + "..." if len(product['title']) > 45 else product['title']
            logger.info(f"  {i}. {short_title}")

            for retry in range(2):
                try:
                    driver.get(product['url'])
                    time.sleep(1.2)
                    break
                except (WebDriverException, TimeoutException):
                    if retry == 1:
                        logger.warning(f"     –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–∞")
                        break
                    time.sleep(1)
                    continue

            if STOP_PARSING:
                break

            try:
                WebDriverWait(driver, 5).until(
                    lambda d: d.execute_script("return document.readyState") == "complete"
                )
            except:
                pass

            prices = extract_prices_fast(driver)

            product_data = {
                'title': product['title'],
                'url': product['url'],
                'index': i,
                '–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞': prices.get('–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞', ''),
                '—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü': prices.get('—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü', ''),
                'regular_price_num': parse_price_to_number(prices.get('–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞', '')),
                'vat_price_num': parse_price_to_number(prices.get('—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü', ''))
            }

            all_products_data.append(product_data)

            price_info = []
            if prices.get('–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞'):
                price_info.append(f"–û–±—ã—á–Ω–∞—è: {prices['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞']}")
            if prices.get('—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'):
                price_info.append(f"–Æ—Ä–ª–∏—Ü–∞: {prices['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü']}")

            if price_info:
                logger.info(f"     {', '.join(price_info)}")
            else:
                logger.info(f"     —Ü–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        except StaleElementReferenceException as e:
            logger.warning(f"     StaleElement –æ—à–∏–±–∫–∞")
            continue
        except Exception as e:
            logger.warning(f"     –û—à–∏–±–∫–∞: {e}")
            continue

    if not all_products_data:
        logger.warning("–ù–∏ –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
        return result

    valid_products = [p for p in all_products_data if p['regular_price_num'] != float('inf')]

    if valid_products:
        best_product = min(valid_products, key=lambda x: x['regular_price_num'])

        result["—Ü–µ–Ω–∞"] = best_product['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞']
        result["—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü"] = best_product['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü']
        result["—Å—Å—ã–ª–∫–∞"] = best_product['url']

        logger.info(f"–õ–£–ß–®–ò–ô –í–´–ë–û–†: —Ç–æ–≤–∞—Ä {best_product['index']} - {best_product['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞']}")

        logger.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–µ–Ω:")
        for p in sorted(all_products_data, key=lambda x: x['regular_price_num']):
            if p['regular_price_num'] != float('inf'):
                marker = "‚Üí –í–´–ë–†–ê–ù" if p == best_product else ""
                logger.info(f"  –¢–æ–≤–∞—Ä {p['index']}: {p['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞']} {marker}")
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ–±—ã—á–Ω—ã—Ö —Ü–µ–Ω, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–æ–≤–∞—Ä —Å –ª—é–±—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        first_product = all_products_data[0]
        result["—Ü–µ–Ω–∞"] = first_product['–æ–±—ã—á–Ω–∞—è —Ü–µ–Ω–∞']
        result["—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü"] = first_product['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü']
        result["—Å—Å—ã–ª–∫–∞"] = first_product['url']

        logger.warning("–û–±—ã—á–Ω—ã–µ —Ü–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–∑—è—Ç –ø–µ—Ä–≤—ã–π —Ç–æ–≤–∞—Ä")

    return result

def smart_search_input(driver, search_term: str, max_retries: int = 3) -> bool:
    """–ù–∞–¥—ë–∂–Ω—ã–π –ø–æ–∏—Å–∫ —Å fallback –Ω–∞ –ø—Ä—è–º–æ–π –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
    normalized_term = _normalize_search_term(search_term)
    if not normalized_term:
        logger.warning("–ü—É—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
        return False

    current_url = driver.current_url or ""
    if 'search' in current_url and 'text=' in current_url:
        logger.debug("–£–∂–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞, –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å")
        success = update_search_query(driver, normalized_term, max_retries)
    else:
        logger.debug("–ù–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –≤—ã–ø–æ–ª–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫")
        success = perform_new_search(driver, normalized_term, max_retries)

    if success:
        return True

    logger.warning("–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ø–æ–ª–µ –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–±—É—é –ø—Ä—è–º–æ–π URL")
    return _perform_direct_search_navigation(driver, normalized_term)

def update_search_query(driver, search_term: str, max_retries: int = 3) -> bool:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""

    search_selectors = [
        'input[name="text"]',
        'input[data-auto="search-input"]',
        'input[placeholder*="–∏—Å–∫–∞—Ç—å" i]',
        'input[placeholder*="–ø–æ–∏—Å–∫" i]',
        '.search-input input',
        '.header-search input',
        '[data-zone="search"] input',
        'input.n-search__input',
        'input[type="search"]',
    ]

    for retry in range(max_retries):
        if STOP_PARSING:
            return False

        try:
            WebDriverWait(driver, 5).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )

            searchbox = None
            for selector in search_selectors:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for candidate in elements:
                    if candidate.is_displayed() and candidate.is_enabled():
                        searchbox = candidate
                        logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –ø–æ–∏—Å–∫–∞: {selector}")
                        break
                if searchbox:
                    break

            if not searchbox:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1}: –ø–æ–ª–µ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                if retry < max_retries - 1:
                    driver.get("https://market.yandex.ru")
                    time.sleep(1)
                    continue
                return False

            driver.execute_script(
                """
                const input = arguments[0];
                const value = arguments[1];
                input.focus();
                input.value = '';
                input.dispatchEvent(new Event('input', { bubbles: true }));
                input.value = value;
                input.dispatchEvent(new Event('input', { bubbles: true }));
                input.dispatchEvent(new Event('change', { bubbles: true }));
                """,
                searchbox,
                search_term,
            )
            searchbox.send_keys(Keys.RETURN)

            WebDriverWait(driver, 8).until(lambda d: 'search' in (d.current_url or ''))
            return True

        except (TimeoutException, StaleElementReferenceException) as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1}: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å ({e})")
            if retry < max_retries - 1:
                time.sleep(1)
                continue
            return False
        except Exception as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1} –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            if retry < max_retries - 1:
                time.sleep(1)
                continue
            return False

    return False

def perform_new_search(driver, search_term: str, max_retries: int = 3) -> bool:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã."""

    selectors = [
        (By.NAME, "text"),
        (By.CSS_SELECTOR, "input[name='text']"),
        (By.CSS_SELECTOR, "[data-auto='search-input']"),
        (By.CSS_SELECTOR, "input[type='search']"),
    ]

    for retry in range(max_retries):
        if STOP_PARSING:
            return False

        try:
            WebDriverWait(driver, 5).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )

            searchbox = None
            for selector_type, selector in selectors:
                elements = driver.find_elements(selector_type, selector)
                for candidate in elements:
                    if candidate.is_displayed() and candidate.is_enabled():
                        searchbox = candidate
                        break
                if searchbox:
                    break

            if not searchbox:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1}: –ø–æ–ª–µ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π")
                if retry < max_retries - 1:
                    driver.get("https://market.yandex.ru")
                    time.sleep(1)
                    continue
                return False

            driver.execute_script(
                """
                const input = arguments[0];
                const value = arguments[1];
                input.focus();
                input.value = '';
                input.dispatchEvent(new Event('input', { bubbles: true }));
                input.value = value;
                input.dispatchEvent(new Event('input', { bubbles: true }));
                input.dispatchEvent(new Event('change', { bubbles: true }));
                """,
                searchbox,
                search_term,
            )
            searchbox.send_keys(Keys.RETURN)

            WebDriverWait(driver, 8).until(lambda d: 'search' in (d.current_url or ''))
            return True

        except (TimeoutException, StaleElementReferenceException) as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1}: —Å–±–æ–π –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ ({e})")
            if retry < max_retries - 1:
                time.sleep(1)
                continue
            return False
        except Exception as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {retry + 1} –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            if retry < max_retries - 1:
                time.sleep(1)
                continue
            return False

    return False

def get_prices(product_name: str, headless: bool = True, driver_path: Optional[str] = None,
              timeout: int = 15, use_business_auth: bool = True) -> Dict[str, str]:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω —Å –≤—ã–±–æ—Ä–æ–º –Ω–∞–∏–º–µ–Ω—å—à–µ–π –∏–∑ 5 –∫–∞—Ä—Ç–æ—á–µ–∫"""
    result = {"—Ü–µ–Ω–∞": "", "—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü": "", "—Å—Å—ã–ª–∫–∞": ""}
    driver = None
    current_profile_path = None

    if STOP_PARSING:
        return result

    try:
        driver = create_driver(headless=headless, driver_path=driver_path, use_auth=use_business_auth)

        driver.get("https://market.yandex.ru/")
        time.sleep(0.5)

        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å —Ç–µ–∫—É—â–µ–≥–æ –¥—Ä–∞–π–≤–µ—Ä–∞ –¥–ª—è —Ç–æ—á–µ—á–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏
        current_profile_path = getattr(driver, "profile_path", None)

        # –ó–∞–≥—Ä—É–∑–∫–∞ cookies –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –ø–æ–∏—Å–∫–∞
        if use_business_auth and not STOP_PARSING:
            load_cookies_for_auth(driver)

        if STOP_PARSING:
            return result

        # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –º–∞—Ä–∫–µ—Ç (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞)
        current_url = driver.current_url
        if 'market.yandex.ru' not in current_url:
            try:
                driver.get("https://market.yandex.ru")
                time.sleep(0.8)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –Ω–∞ –º–∞—Ä–∫–µ—Ç: {e}")
                return result

        if STOP_PARSING:
            return result

        # –£–õ–£–ß–®–ï–ù–ù–´–ô –ø–æ–∏—Å–∫ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        search_success = smart_search_input(driver, product_name)
        if not search_success:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫")
            return result

        if STOP_PARSING:
            return result

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤
        products = extract_products_smart(driver)
        if not products:
            logger.warning("–¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return result

        if STOP_PARSING:
            return result

        # –°–æ–±–∏—Ä–∞–µ–º —Ü–µ–Ω—ã —Å–æ –í–°–ï–• —Ç–æ–≤–∞—Ä–æ–≤ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ù–ê–ò–ú–ï–ù–¨–®–£–Æ
        result = collect_prices_from_all_products(driver, products, product_name)

        return result

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_name[:30]}...: {e}")
        return result

    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
        if current_profile_path:
            success = cleanup_single_profile(current_profile_path)
            if success:
                CREATED_PROFILES.discard(current_profile_path)

def _make_product_cache_key(product_name: str) -> str:
    """–ö–ª—é—á –∫—ç—à–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤."""
    return re.sub(r"\s+", " ", str(product_name or "")).strip().lower()

def parse_tender_excel(input_file: str, output_file: str, headless: bool = True,
                      workers: int = 1, driver_path: Optional[str] = None,
                      auto_save: bool = True, use_business_auth: bool = False) -> pd.DataFrame:
    """–û–°–ù–û–í–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏ –¢–ï–ù–î–ï–†–ù–´–ú –§–û–†–ú–ê–¢–û–ú"""
    global STOP_PARSING, CURRENT_DATAFRAME, CURRENT_OUTPUT_FILE, CURRENT_INPUT_FILE

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
    setup_signal_handlers()

    STOP_PARSING = False
    CURRENT_INPUT_FILE = input_file
    CURRENT_OUTPUT_FILE = output_file


    items = extract_products_from_excel(input_file)
    if items.empty:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–≤–∞—Ä—ã –≤ —Ñ–∞–π–ª–µ")

    # DataFrame –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞—Ä—Å–∏–Ω–≥–∞
    df = pd.DataFrame({
        '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ': items['name'],
        '—Ü–µ–Ω–∞': '',
        '—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü': '',
        '—Å—Å—ã–ª–∫–∞': ''
    })

    CURRENT_DATAFRAME = df  # –î–ª—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

    effective_workers = max(1, int(workers or 1))
    if effective_workers != 1:
        logger.warning("–ü–∞—Ä–∞–º–µ—Ç—Ä workers —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ")

    auth_text = "—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π" if use_business_auth else "–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"
    logger.info(f"–ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} —Ç–æ–≤–∞—Ä–æ–≤ {auth_text}")
    logger.info("üîÑ –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ê–ö–¢–ò–í–ù–û")
    logger.info("üìã –†–ï–ó–£–õ–¨–¢–ê–¢: —Ç–µ–Ω–¥–µ—Ä–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å –∫–æ–ª–æ–Ω–∫–æ–π '–Ø–Ω–¥–µ–∫—Å –ú–∞—Ä–∫–µ—Ç'")
    logger.info("–†–µ–∂–∏–º: –ø–æ–∏—Å–∫ –Ω–∞–∏–º–µ–Ω—å—à–µ–π —Ü–µ–Ω—ã —Å—Ä–µ–¥–∏ 5 –∫–∞—Ä—Ç–æ—á–µ–∫")

    cache: Dict[str, Dict[str, str]] = {}

    try:
        for idx, row in enumerate(df.itertuples(index=False), start=1):
            if STOP_PARSING:
                logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                break

            try:
                product_name = row.–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {idx}/{len(df)} - {product_name[:40]}...")

                cache_key = _make_product_cache_key(product_name)
                if cache_key in cache:
                    prices = cache[cache_key]
                    logger.info(f"–ü–æ–≤—Ç–æ—Ä —Ç–æ–≤–∞—Ä–∞, –∏—Å–ø–æ–ª—å–∑—É—é –∫—ç—à: {product_name[:40]}...")
                else:
                    prices = get_prices(product_name, headless, driver_path, 20, use_business_auth)
                    if any(prices.get(k) for k in ("—Ü–µ–Ω–∞", "—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü", "—Å—Å—ã–ª–∫–∞")):
                        cache[cache_key] = prices.copy()

                row_idx = idx - 1
                df.at[row_idx, '—Ü–µ–Ω–∞'] = prices.get('—Ü–µ–Ω–∞', '')
                df.at[row_idx, '—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'] = prices.get('—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü', '')
                df.at[row_idx, '—Å—Å—ã–ª–∫–∞'] = prices.get('—Å—Å—ã–ª–∫–∞', '')

                # –õ–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                price_summary = []
                if prices.get('—Ü–µ–Ω–∞'):
                    price_summary.append(f"–õ—É—á—à–∞—è —Ü–µ–Ω–∞: {prices['—Ü–µ–Ω–∞'][:15]}")
                if prices.get('—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'):
                    price_summary.append(f"–î–ª—è —é—Ä–ª–∏—Ü: {prices['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'][:15]}")

                if price_summary:
                    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {idx}/{len(df)}: {', '.join(price_summary)}")
                else:
                    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {idx}/{len(df)}: —Ü–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

                # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 3 —Ç–æ–≤–∞—Ä–∞ –í –¢–ï–ù–î–ï–†–ù–û–ú –§–û–†–ú–ê–¢–ï
                if auto_save and idx % 3 == 0:
                    try:
                        save_results_into_tender_format(input_file, output_file, df)
                        logger.info(f"–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–Ω–¥–µ—Ä–∞: {idx}/{len(df)}")
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ç–æ–≤–∞—Ä–∞ {idx}: {e}")
                df.at[idx - 1, '—Ü–µ–Ω–∞'] = "–û–®–ò–ë–ö–ê"
                df.at[idx - 1, '—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'] = "–û–®–ò–ë–ö–ê"

    finally:
        cleanup_profiles()
        CURRENT_DATAFRAME = None  # –û—á–∏—â–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –í –¢–ï–ù–î–ï–†–ù–û–ú –§–û–†–ú–ê–¢–ï
    if output_file != "auto":
        save_results_into_tender_format(input_file, output_file, df)
        logger.info(f"üéØ –¢–ï–ù–î–ï–†–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ì–û–¢–û–í–ê: {output_file}")
        logger.info("üìä –°–æ–∑–¥–∞–Ω–∞ —Ç–æ—á–Ω–∞—è –∫–æ–ø–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ + –∫–æ–ª–æ–Ω–∫–∞ '–Ø–Ω–¥–µ–∫—Å –ú–∞—Ä–∫–µ—Ç'")

    return df

if __name__ == "__main__":
    test_product = "–¢–æ—á–∫–∞ –¥–æ—Å—Ç—É–ø–∞ Ubiquiti UniFi AC Pro AP"
    print("–¢–µ—Å—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ —Å —Ç–µ–Ω–¥–µ—Ä–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º...")
    result = get_prices(test_product, headless=False, use_business_auth=True)

    print(f"–¢–æ–≤–∞—Ä: {test_product}")
    print(f"–õ—É—á—à–∞—è —Ü–µ–Ω–∞: {result['—Ü–µ–Ω–∞']}")
    print(f"–¶–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü: {result['—Ü–µ–Ω–∞ –¥–ª—è —é—Ä–ª–∏—Ü'] or '–ù–ï –ù–ê–ô–î–ï–ù–ê'}")
    print(f"–°—Å—ã–ª–∫–∞: {result['—Å—Å—ã–ª–∫–∞']}")
    print("-" * 50)
